{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben Needs a Friend - LLM Agent for event listings\n",
    "This is part of the \"Ben Needs a Friend\" tutorial. See all the notebooks and materials [here](https://github.com/bpben/ben_friend_25). Follow setup instructions there to use this notebook.\n",
    "\n",
    "In this notebook, we set up a simple workflow for an agent to suggest some cool events from the [Boston Calendar](https://www.thebostoncalendar.com/).  \n",
    "\n",
    "Since this requires a larger model than we've used in other notebooks, it will not work on Codespaces unless you switch to using an LLM provider like OpenAI.  \n",
    "\n",
    "If you are using OpenAI:\n",
    "- This has been tested with GPT-4o \n",
    "- You will need to set an environment variable `OPENAI_API_KEY` with your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import sample\n",
    "from llamabot import  AgentBot, SimpleBot, tool\n",
    "\n",
    "\n",
    "agent_model = \"qwen2.5:7b\"\n",
    "openai_model = 'gpt-4o' # llamabot requires a model with structured output features\n",
    "friend_model = \"llama3.1:8b\"\n",
    "\n",
    "friend_prompt = \"\"\"Your name is Friend. \\\n",
    "You are having a conversation with your close friend Ben. \\\n",
    "You and Ben are sarcastic and poke fun at one another. \\\n",
    "But you care about each other and support one another.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba17a8c",
   "metadata": {},
   "source": [
    "### Using AgentBot\n",
    "Our first example uses llamabot's `AgentBot`.  This is pretty experimental, but I think it displays some components of a simple bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84966ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bot\n",
    "bot = AgentBot(\n",
    "    system_prompt=friend_prompt,\n",
    "    functions=[],\n",
    "    model_name=f\"ollama_chat/{agent_model}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6467cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bot(\"What day is it today?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25ed53",
   "metadata": {},
   "source": [
    "This will almost always be wrong.  Why? Because our friend doesn't have access to a calendar! Let's fix that by defining a `tool`\n",
    "\n",
    "Note - this will not always work, even with an 8 billion parameter model.  More on that in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def today(text: str) -> str:\n",
    "    \"\"\"Returns today's date, use this when you need to get today's date.\\\n",
    "    The input should always be an empty string.\"\"\"\n",
    "    return datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f566941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at what is being provided to the model\n",
    "print(today.json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed732b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bot\n",
    "bot = AgentBot(\n",
    "    system_prompt=friend_prompt,\n",
    "    functions=[today,],\n",
    "    # often this will not work and we will need to use openai\n",
    "    # model_name=f\"ollama_chat/{agent_model}\"\n",
    "    model_name='gpt-4o'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt has been extended with additional information\n",
    "bot.decision_bot.system_prompt.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8845aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5038017",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bot(\"What day is it today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece0a28",
   "metadata": {},
   "source": [
    "It usually takes a few tries, but this typically work.\n",
    "\n",
    "### Finding local events\n",
    "A good friend will invite you to cool local events.  So why don't we give our AI friend access to that capability?\n",
    "\n",
    "Our implementation here will scrape [The Boston Calendar](https://www.thebostoncalendar.com) and return a random assortment of events from there.\n",
    "\n",
    "The result of the agent workflow should be telling us about all these cool events.  \n",
    "\n",
    "This will often fail with a smaller model, we'll likely need to switch to using OpenAI's model to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eea344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_for_calendar(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Utility for converting text input to boston calendar URL\n",
    "    \"\"\"\n",
    "    if len(text) == 1:\n",
    "        # will assume today's month if we're looking at weekend number\n",
    "        today = datetime.now()\n",
    "        month = today.month\n",
    "        day = today.day\n",
    "        year = today.year\n",
    "        url = f'https://www.thebostoncalendar.com/events?day={day}&month={month}&weekend={text}&year={year}'\n",
    "    # this will fail if the string provided is not a date\n",
    "    else:\n",
    "        try:\n",
    "            f_date = datetime.strptime(text, '%Y-%m-%d')\n",
    "            day_of_month = f_date.day\n",
    "            month = f_date.month\n",
    "            year = f_date.year\n",
    "            url = f'https://www.thebostoncalendar.com/events?day={day_of_month}&month={month}&year={year}'\n",
    "        except ValueError:\n",
    "            return \n",
    "    return url\n",
    "\n",
    "def weekend(text: str) -> str:\n",
    "    \"\"\"Returns the single-digit weekend number for this weekend, \\\n",
    "    use this for any questions related to the weekend date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return the weekend number.\"\"\"\n",
    "    today = datetime.now()\n",
    "    \n",
    "    # Calculate the weekend number within the month\n",
    "    first_day_of_month = today.replace(day=1)\n",
    "    weekend_number_within_month = (today - first_day_of_month).days // 7 + 1\n",
    "\n",
    "    return weekend_number_within_month\n",
    "\n",
    "@tool\n",
    "def get_events(text: str) -> str:\n",
    "    \"\"\"Returns information about local events. \\ \n",
    "    The input is either a date string in the format YYYY-MM-DD, \\\n",
    "    or it is a single-digit weekend number.\\\n",
    "    This function will return a list where \\\n",
    "    each element contains an event name, date and location as a tuple.\\\n",
    "    This function should be used to provide complete information about events.\"\"\"\n",
    "    # use the parsing utility to get a formatted url\n",
    "    url = parse_for_calendar(text)\n",
    "    if url is None:\n",
    "        # give the LLM a useful response\n",
    "        return f'Input \"{text}\" is not in the right format - it needs to be a date string or a weekend number'\n",
    "    response = requests.get(url)     \n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract data\n",
    "    events = soup.find_all('div', class_='info')\n",
    "\n",
    "    all_events = []\n",
    "    # gather the first 3 events\n",
    "    select_events = []\n",
    "    # there's now a lot of constant pinned events\n",
    "    for i, event in enumerate(events[10:]):\n",
    "        if i > 2:\n",
    "            break\n",
    "        title = event.find('h3').text.strip()\n",
    "        date = event.find('p', class_='time').text.strip()\n",
    "        location = event.find('p', class_='location').text.strip()\n",
    "        select_events.append((title, date, location))\n",
    "    \n",
    "    return select_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a26628",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_bot = AgentBot(\n",
    "    system_prompt=friend_prompt,\n",
    "    functions=[get_events, today ],\n",
    "    model_name=f\"ollama_chat/{agent_model}\",\n",
    "    #model_name='gpt-4o'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd749776",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = friend_bot(\"What events are happening today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffe0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_bot.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b622e9",
   "metadata": {},
   "source": [
    "If we use a large model, this will usually produce a useful response, even with the proper \"friend\" style.  But if you use the normal system prompt, sometimes you get more information.  \n",
    "\n",
    "What if we split up this task? We'll depend on OpenAI to retrieve the information, but our smaller model to \"style\" it.  This what we might consider a \"multi-agent\" system.  \n",
    "\n",
    "With llamabot, this is not implemented, but we can do a hack where we just wrap a simple bot in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a styling prompt\n",
    "styling_prompt = \"\"\"Your name is Friend. \\\n",
    "You are having a conversation with your close friend Ben. \\\n",
    "You and Ben are sarcastic and poke fun at one another. \\\n",
    "But you care about each other and support one another. \n",
    "\n",
    "You know the following information:\n",
    "{events_output}\"\"\"\n",
    "\n",
    "@tool\n",
    "def style_response(event_info: list, user_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Utility for applying \"Friend\" style to the event information. \\\n",
    "    Use this after gathering event information.\n",
    "    \"\"\"\n",
    "    # Convert the list of tuples to a string\n",
    "    event_info_str = \"\\n\".join([f\"Event: {event[0]}, Date: {event[1]}, Location: {event[2]}\" for event in event_info])\n",
    "\n",
    "    filled_styling_prompt = styling_prompt.format(events_output=event_info_str)\n",
    "    \n",
    "    styler_agent = SimpleBot(\n",
    "        system_prompt=filled_styling_prompt,\n",
    "      model_name=f\"ollama_chat/{agent_model}\",\n",
    "    )\n",
    "\n",
    "    return styler_agent(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = style_response([('PhotoWalks Beacon Hill Tour', 'Wednesday, May 07, 2025 1:00p', 'Beacon Hill'), ('Film Screening: Exit Through the Gift Shop', 'Wednesday, May 07, 2025 2:00p', 'Harvard Art Museums'), ('Girls Can Be Engineers: An In-person Book Reading with Author and Engineer Jamila H. Lindo at Discovery Museum', 'Wednesday, May 07, 2025 3:00p', 'Discovery Museum')],\n",
    "               \"What events are happening today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4409f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_agent_bot = AgentBot(\n",
    "    system_prompt=friend_prompt,\n",
    "    functions=[get_events, today, style_response],\n",
    "    model_name='gpt-4o'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb865be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = multi_agent_bot(\"What events are happening today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
